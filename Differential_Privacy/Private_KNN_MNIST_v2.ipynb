{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Private_KNN_MNIST_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFmtgMp1ERdI"
      },
      "source": [
        "## This is a KNN classification algorithm that aims to best classify images from the MNIST Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIto8kIIERdQ"
      },
      "source": [
        "#Relevant imports\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sc\n",
        "import pandas as pd\n",
        "import math\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from collections import Counter\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me1KungaERdR"
      },
      "source": [
        "## What is this?\n",
        "This is a particular implementation of the KNN algorithm for classifying images in the MNIST dataset. Here, a eculidean distance metric is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23rjsj84ERdR"
      },
      "source": [
        "train = pd.read_csv(\"/content/mnist_train.csv\")\n",
        "test = pd.read_csv(\"/content/mnist_test.csv\")\n",
        "\n",
        "#Do poisson sampling\n",
        "sample = train.sample(frac = .05)\n",
        "\n",
        "global X_train, X_test, y_train, y_test\n",
        "#set up test train data\n",
        "X_train = sample.drop(columns='label')\n",
        "\n",
        "X_test = test.drop(columns = 'label')\n",
        "\n",
        "y_train = sample['label']\n",
        "\n",
        "y_test = test['label']\n",
        "\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "X_test = X_test.to_numpy()\n",
        "\n",
        "y_train = y_train.to_numpy()\n",
        "\n",
        "X_train = X_train.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLwd7qK-ERdS"
      },
      "source": [
        "#Euclidean distance betweeen two arrays\n",
        "# np.sum((row1 - row2)**2 )\n",
        "def shortestDistance(row1, row2):\n",
        "        return math.sqrt(np.sum((row1-row2)**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnAaK7BLERdS"
      },
      "source": [
        "#KNN driver, return the \n",
        "#pass index of the training point and the distances between all the other clusters\n",
        "#iterator construct?\n",
        "# N = number of images in the dataset,\n",
        "# K number of neighbors\n",
        "def knn(train_x, train_y, point, k):\n",
        "    #List to store distances\n",
        "    distances =[]\n",
        "    \n",
        "    #List to store neighbors\n",
        "    k_nearest_neighbors = []\n",
        "    \n",
        "    #Variable to increment along the training set labels\n",
        "    i = 0\n",
        "    \n",
        "    #iterate over the training set\n",
        "    for training_point in train_x:\n",
        "        #Add the euclidean distance between the training point and test point \n",
        "        distances.append((shortestDistance(training_point,point),train_y[i]))\n",
        "        #Increment over the testing set \n",
        "        i = i+1\n",
        "    #sort the distances\n",
        "    sorted_distances = sorted(distances, key = lambda x:x[0])\n",
        "    #Get the top k matches\n",
        "    for i in range(k):\n",
        "        k_nearest_neighbors.append(sorted_distances.pop(1))\n",
        "    #Get the frequency using numpy functions, then return the closest label\n",
        "    k_nearest_neighbors = np.asarray(k_nearest_neighbors)\n",
        "    frequencies = np.unique(k_nearest_neighbors[:,1],return_counts = True)\n",
        "    labels,counts = frequencies\n",
        "    maj = labels[counts.argmax()]\n",
        "    return maj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QdHeMJzf1Tv"
      },
      "source": [
        "#Driver class as to run the KNN algorithm\n",
        "#Keep track of a confusion matrix: 0-9, measure the number of the counts of decisions.\n",
        "#Iterate over pairs, run the prediction to lessen memory usage.\n",
        "def driver_2(new_train_data, new_test_data,k):\n",
        "\n",
        "    counter = 0\n",
        "    predictions = []\n",
        "    actual_predictions = []\n",
        "    rejected = []\n",
        "    right = 0\n",
        "\n",
        "    predictions = []\n",
        "    #Iterate over the test set to make predictions\n",
        "    for element in new_train_data:\n",
        "        #make a prediction using a KNN\n",
        "        predictions.append(knn(X_train, y_train,element,k))\n",
        "    #Print the accuracy\n",
        "    print(100*(np.array(predictions) == new_test_data).sum() / new_test_data.shape[0])\n",
        "    print(\"Confusion Matrix \\n\")\n",
        "    confusion_matrix(new_test_data,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWbXSCM9ERdS"
      },
      "source": [
        "#Driver class as to run the KNN algorithm\n",
        "#Keep track of a confusion matrix: 0-9, measure the number of the counts of decisions.\n",
        "#Iterate over pairs, run the prediction to lessen memory usage.\n",
        "def main():\n",
        "    #read user input on the number of neighbors to find\n",
        "    k = input(\"Enter number of neighbors: \")\n",
        "    k = int(k)\n",
        "    counter = 0\n",
        "    noised_predictions = []\n",
        "    actual_predictions = []\n",
        "    tester = []\n",
        "    right = 0\n",
        "\n",
        "    #Iterate over the test set to make predictions\n",
        "    for element in X_test:\n",
        "        #make a prediction using a KNN\n",
        "        pred = knn(X_train, y_train,element,k)\n",
        "        actual_predictions.append(pred)\n",
        "        if pred == y_test[counter]:\n",
        "            right = right+1\n",
        "        noise = np.random.normal(0, 1, 1)\n",
        "        pred = pred + noise\n",
        "        if pred > 0.6*k:\n",
        "            noised_predictions.append(pred)\n",
        "            tester.append(y_test[counter])\n",
        "        counter = counter+1\n",
        "\n",
        "    noised = np.array(noised_predictions)\n",
        "    new_y = np.array(tester)\n",
        "    print(noised)\n",
        "    print(new_y)\n",
        "    driver_2(noised,new_y,k)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}